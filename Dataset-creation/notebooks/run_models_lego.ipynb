{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# stds = list(range(5, 65, 5))\n",
    "# stds = list(range(5, 15, 5))\n",
    "# stds = [i/1000 for i in stds]\n",
    "# print(stds)\n",
    "stds = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.0525, 0.055, 0.0575, 0.06]\n",
    "path_lego = 'C:\\Stuff\\Dataset-creation\\data_lego\\lego'\n",
    "num_iterations = 15000\n",
    "\n",
    "types = ['position', 'orientation']\n",
    "for type in types:\n",
    "    for std in stds:\n",
    "        command = f'ns-train nerfacto --data {path_lego} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name lego-{type}-std-{std} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.{type}-noise-std {std} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'--pipeline.model.near-plane 2. ' \\\n",
    "                f'--pipeline.model.far-plane 6.' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "                f'--pipeline.model.use-average-appearance-embedding False ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {type}-std={std} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)\n",
    "\n",
    "for std in stds:\n",
    "    command = f'ns-train nerfacto --data {path_lego} ' \\\n",
    "            f'--viewer.quit-on-train-completion True ' \\\n",
    "            f'--project-name lego-pos-orient-std-{std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[0]}-noise-std {std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[1]}-noise-std {std} ' \\\n",
    "            f'--max-num-iterations {num_iterations} ' \\\n",
    "            f'--pipeline.model.near-plane 2. ' \\\n",
    "            f'--pipeline.model.far-plane 6.' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "            f'--pipeline.model.use-average-appearance-embedding False ' \\\n",
    "            f'nerfstudio-data --eval-mode filename'\n",
    "\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    process.wait()\n",
    "    return_code = process.returncode\n",
    "\n",
    "    with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "        text_to_write = f'The command at pos-std={std} and orient-std={std} exited with code: {return_code}\\n'\n",
    "        file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "########## ЖАТЬ СЮДА ЛИЗА ОК????!?!??!?!\n",
    "#################\n",
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "pathes_datasets=[\n",
    "# 'C:\\Stuff\\Dataset-creation\\data_lego\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data_lego\\lego-pns-noise',\n",
    "'C:\\Stuff\\Dataset-creation\\data_lego\\lego-sparce',\n",
    "'C:\\Stuff\\Dataset-creation\\data_lego\\lego-gamma',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "'C:\\Stuff\\Dataset-creation\\data_lego\\lego-saturation',]\n",
    "\n",
    "path_lego = 'C:\\Stuff\\Dataset-creation\\data_lego\\lego'\n",
    "num_iterations = 15000\n",
    "\n",
    "types = ['position', 'orientation']\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train nerfacto --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'--pipeline.model.near-plane 2. ' \\\n",
    "                f'--pipeline.model.far-plane 6. ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "                f'--pipeline.model.use-average-appearance-embedding False ' \\\n",
    "                f'blender-data ' \\\n",
    "        \n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\lego_outputs.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# pathes_datasets=[\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',]\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "path_lego = 'C:\\Stuff\\Dataset-creation\\data\\lego'\n",
    "num_iterations = 15000\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train nerfacto --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "changed version from \"eval_run.ipynb\"\n",
    "here each (i%2 != 1) run is rendered, because in original \"eval_run\" its \"i%2==1\"\n",
    "but since i need all of the runs rendered, this code extends what left \n",
    "'''\n",
    "\n",
    "import re\n",
    "import yaml\n",
    "import subprocess\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "model_type = 'nerfacto'\n",
    "path_outputs = 'C:\\Stuff\\Dataset-creation\\\\notebooks\\outputs'\n",
    "i = 0\n",
    "# for i, degradation_type in enumerate(os.listdir(path_outputs)[1:]):\n",
    "for degradation_type in os.listdir(path_outputs)[1:]:\n",
    "    runs = os.path.join(path_outputs, degradation_type, model_type)\n",
    "    # for i, run in enumerate(os.listdir(runs)):\n",
    "    for run in os.listdir(runs):\n",
    "        run_config_path = os.path.join(runs, run, 'config.yml') \n",
    "        project_name = extract_project_name_from_yaml(run_config_path)\n",
    "        path_render = os.path.join('C:\\\\Stuff\\\\Dataset-creation\\\\renders', run)\n",
    "        \n",
    "        base_command =   f'ns-eval --load-config={run_config_path} ' \\\n",
    "                        f'--output-path={project_name}.json '             \n",
    "        render_command = f'--render-output-path={path_render} '\n",
    "        \n",
    "        if i % 2 != 1:\n",
    "          command = base_command + render_command\n",
    "        else:\n",
    "          command = base_command\n",
    "        i += 1\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode                \n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\renders_output.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {project_name} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ngp\n",
    "'''\n",
    "\n",
    "import re\n",
    "import yaml\n",
    "import subprocess\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'instant-ngp-bounded'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ngp pos+orient noises\n",
    "'''\n",
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stds = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.0525, 0.055, 0.0575, 0.06, 0.0625, 0.065, 0.0675, 0.07]\n",
    "path_lego = 'C:\\Stuff\\Dataset-creation\\data\\lego'\n",
    "num_iterations = 15000\n",
    "model_type = 'instant-ngp-bounded'\n",
    "\n",
    "types = ['position', 'orientation']\n",
    "for type in types:\n",
    "    for std in stds:\n",
    "        command = f'ns-train {model_type} --data {path_lego} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name lego-{type}-std-{std} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.{type}-noise-std {std} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "            text_to_write = f'The command for {model_type} at {type}-std={std} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)\n",
    "\n",
    "for std in stds:\n",
    "    command = f'ns-train {model_type} --data {path_lego} ' \\\n",
    "            f'--viewer.quit-on-train-completion True ' \\\n",
    "            f'--project-name lego-pos-orient-std-{std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[0]}-noise-std {std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[1]}-noise-std {std} ' \\\n",
    "            f'--max-num-iterations {num_iterations} ' \\\n",
    "            f'nerfstudio-data --eval-mode filename'\n",
    "\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    process.wait()\n",
    "    return_code = process.returncode\n",
    "\n",
    "    with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "        text_to_write = f'The command for {model_type} at pos-std={std} and orient-std={std} exited with code: {return_code}\\n'\n",
    "        file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ngp optimizer off\n",
    "'''\n",
    "\n",
    "import re\n",
    "import yaml\n",
    "import subprocess\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'instant-ngp-bounded'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)\n",
    "\n",
    "\n",
    "\n",
    "stds = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.0525, 0.055, 0.0575, 0.06, 0.0625, 0.065, 0.0675, 0.07]\n",
    "path_lego = 'C:\\Stuff\\Dataset-creation\\data\\lego'\n",
    "num_iterations = 15000\n",
    "model_type = 'instant-ngp-bounded'\n",
    "\n",
    "types = ['position', 'orientation']\n",
    "for type in types:\n",
    "    for std in stds:\n",
    "        command = f'ns-train {model_type} --data {path_lego} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name lego-{type}-std-{std} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.{type}-noise-std {std} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "            text_to_write = f'The command for {model_type} at {type}-std={std} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)\n",
    "\n",
    "for std in stds:\n",
    "    command = f'ns-train {model_type} --data {path_lego} ' \\\n",
    "            f'--viewer.quit-on-train-completion True ' \\\n",
    "            f'--project-name lego-pos-orient-std-{std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[0]}-noise-std {std} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.{types[1]}-noise-std {std} ' \\\n",
    "            f'--max-num-iterations {num_iterations} ' \\\n",
    "            f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "            f'nerfstudio-data --eval-mode filename'\n",
    "\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    process.wait()\n",
    "    return_code = process.returncode\n",
    "\n",
    "    with open('C:\\Stuff\\Dataset-creation\\output.txt', 'a') as file:\n",
    "        text_to_write = f'The command for {model_type} at pos-std={std} and orient-std={std} exited with code: {return_code}\\n'\n",
    "        file.write(text_to_write)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nerfacto optimizer on, offset subset\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'nerfacto'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nerfacto optimizer on, offset 5 subset\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset-5',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'nerfacto'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nerfacto optimizer off, offset 5 subset\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset-5',\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'nerfacto'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'--pipeline.datamanager.camera-optimizer.mode off ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nerfacto optimizer on, offset random only 1/6 images\n",
    "'''\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value\n",
    "\n",
    "pathes_datasets=[\n",
    "'C:\\Stuff\\Dataset-creation\\data\\lego-original-offset-random',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset-5',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce-offset',]\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-pns-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-noise',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-range',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-saturation',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-gamma',\n",
    "# 'C:\\Stuff\\Dataset-creation\\data\\lego-sparce',]\n",
    "\n",
    "num_iterations = 15000\n",
    "model_type = 'nerfacto'\n",
    "\n",
    "for path_dataset in pathes_datasets:\n",
    "    for folder in os.listdir(path_dataset):\n",
    "        path_sub_dataset = os.path.join(path_dataset, folder)\n",
    "        command = f'ns-train {model_type} --data {path_sub_dataset} ' \\\n",
    "                f'--viewer.quit-on-train-completion True ' \\\n",
    "                f'--project-name {folder} ' \\\n",
    "                f'--max-num-iterations {num_iterations} ' \\\n",
    "                f'nerfstudio-data --eval-mode filename' \\\n",
    "\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        with open('C:\\Stuff\\Dataset-creation\\\\newoutput.txt', 'a') as file:\n",
    "            text_to_write = f'The command at {folder} with model {model_type} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
