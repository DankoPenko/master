{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for ranges look up into \"split_by_heights.ipynb\"\n",
    "'''\n",
    "\n",
    "import re \n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stump-noise-std-112\n",
      "112\n",
      "stump-noise-std-128\n",
      "128\n",
      "stump-noise-std-16\n",
      "16\n",
      "stump-noise-std-32\n",
      "32\n",
      "stump-noise-std-48\n",
      "48\n",
      "stump-noise-std-64\n",
      "64\n",
      "stump-noise-std-80\n",
      "80\n",
      "stump-noise-std-96\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "# noise\n",
    "def add_noise(image_path, noise_factor):\n",
    "    image = Image.open(image_path)\n",
    "    image = np.array(image)\n",
    "    noise = np.random.normal(scale=noise_factor, size=image.shape)\n",
    "    noisy_image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "\n",
    "path_folder = f'C:\\Stuff\\Dataset-creation\\data\\stump-noise'\n",
    "\n",
    "for folder in os.listdir(path_folder):\n",
    "    std = int(re.findall(r'\\d+', folder)[0])\n",
    "    print(folder)\n",
    "    print(std)\n",
    "    path_image_folder = os.path.join(path_folder, folder, 'images')\n",
    "    for image in os.listdir(path_image_folder):\n",
    "        if 'train' in image:\n",
    "            path_image = os.path.join(path_image_folder, image)\n",
    "            noisy_image = add_noise(path_image, noise_factor=std)\n",
    "            noisy_image.save(path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m144\u001b[39m,\u001b[38;5;241m16\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "list(range(16,144,16))\n",
    "list(range(0.05, 1.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done stump-pns-green-noise-percent-10 with std 0.1\n",
      "done stump-pns-green-noise-percent-15 with std 0.15\n",
      "done stump-pns-green-noise-percent-20 with std 0.2\n",
      "done stump-pns-green-noise-percent-25 with std 0.25\n",
      "done stump-pns-green-noise-percent-30 with std 0.3\n",
      "done stump-pns-green-noise-percent-35 with std 0.35\n",
      "done stump-pns-green-noise-percent-40 with std 0.4\n",
      "done stump-pns-green-noise-percent-5 with std 0.05\n",
      "done stump-pns-blue-noise-percent-10 with std 0.1\n",
      "done stump-pns-blue-noise-percent-15 with std 0.15\n",
      "done stump-pns-blue-noise-percent-20 with std 0.2\n",
      "done stump-pns-blue-noise-percent-25 with std 0.25\n",
      "done stump-pns-blue-noise-percent-30 with std 0.3\n",
      "done stump-pns-blue-noise-percent-35 with std 0.35\n",
      "done stump-pns-blue-noise-percent-40 with std 0.4\n",
      "done stump-pns-blue-noise-percent-5 with std 0.05\n",
      "done stump-pns-red-noise-percent-10 with std 0.1\n",
      "done stump-pns-red-noise-percent-15 with std 0.15\n",
      "done stump-pns-red-noise-percent-20 with std 0.2\n",
      "done stump-pns-red-noise-percent-25 with std 0.25\n",
      "done stump-pns-red-noise-percent-30 with std 0.3\n",
      "done stump-pns-red-noise-percent-35 with std 0.35\n",
      "done stump-pns-red-noise-percent-40 with std 0.4\n",
      "done stump-pns-red-noise-percent-5 with std 0.05\n"
     ]
    }
   ],
   "source": [
    "colors_dict = {'red': 0, 'green': 1, 'blue': 2}\n",
    "\n",
    "def get_true_indices(mask):\n",
    "    return np.transpose(np.nonzero(mask))\n",
    "\n",
    "def add_noise(image_path, salt_prob, pepper_prob, color):\n",
    "    image = Image.open(image_path)\n",
    "    salt_mask = np.random.rand(image.size[1], image.size[0]) < salt_prob\n",
    "    pepper_mask = np.random.rand(image.size[1], image.size[0]) < pepper_prob\n",
    "\n",
    "    indices_salt = get_true_indices(salt_mask)\n",
    "    indices_pepper = get_true_indices(pepper_mask)\n",
    "\n",
    "    noisy_image = np.array(image)\n",
    "\n",
    "    color_id = colors_dict[color]\n",
    "\n",
    "    noisy_image[indices_salt[:, 0], indices_salt[:, 1], color_id] = 255.0\n",
    "    noisy_image[indices_pepper[:, 0], indices_pepper[:, 1], color_id] = 0.0\n",
    "\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "path_folder = 'C:\\\\Stuff\\\\Dataset-creation\\\\data\\\\stump-pns-noise'\n",
    "\n",
    "for color in ['green', 'blue', 'red']:\n",
    "    for folder in os.listdir(path_folder):\n",
    "        if color in folder:\n",
    "            std = int(re.findall(r'\\d+', folder)[0])/100\n",
    "            salt_prob = pepper_prob = std\n",
    "            path_image_folder = os.path.join(path_folder, folder, 'images')\n",
    "            for image in os.listdir(path_image_folder):\n",
    "                if 'train' in image:\n",
    "                    path_image = os.path.join(path_image_folder, image)\n",
    "                    noisy_image = add_noise(path_image, salt_prob, pepper_prob, color=color)\n",
    "                    noisy_image.save(path_image)\n",
    "            print(f'done {folder} with std {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done stump-saturation-std-0.1 with std 0.1\n",
      "done stump-saturation-std-0.2 with std 0.2\n",
      "done stump-saturation-std-0.3 with std 0.3\n",
      "done stump-saturation-std-0.4 with std 0.4\n",
      "done stump-saturation-std-0.5 with std 0.5\n",
      "done stump-saturation-std-0.6 with std 0.6\n",
      "done stump-saturation-std-0.7 with std 0.7\n",
      "done stump-saturation-std-0.8 with std 0.8\n",
      "done stump-saturation-std-0.9 with std 0.9\n",
      "done stump-saturation-std-1.0 with std 1.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def random_saturate(image_path, scale):\n",
    "    image = cv2.imread(image_path)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "    saturation_factor = np.random.normal(loc = 1.0, scale = scale)\n",
    "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * saturation_factor, 0, 255)\n",
    "    saturated_image = cv2.cvtColor(hsv_image.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "    return saturated_image\n",
    "\n",
    "path_folder = 'C:\\Stuff\\Dataset-creation\\data\\stump-saturation'\n",
    "\n",
    "for folder in os.listdir(path_folder):\n",
    "    pattern = re.compile(r'\\d+\\.\\d+')\n",
    "    matches = pattern.findall(folder)\n",
    "    std = float(matches[0])\n",
    "\n",
    "    path_image_folder = os.path.join(path_folder, folder, 'images')\n",
    "    for image in os.listdir(path_image_folder):\n",
    "        if 'train' in image:\n",
    "            path_image = os.path.join(path_image_folder, image)\n",
    "            noisy_image = random_saturate(path_image, scale=std)\n",
    "            cv2.imwrite(path_image, noisy_image)\n",
    "    print(f'done {folder} with std {std}')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from PIL import Image\n",
    "import re\n",
    "import os \n",
    "import random\n",
    "def adjust_gamma(image_path, gamma=1.5):\n",
    "    image = Image.open(image_path)\n",
    "    img_array = np.array(image)\n",
    "    adjusted_img_array = 255 * (img_array / 255) ** gamma\n",
    "    adjusted_img_array = np.clip(adjusted_img_array, 0, 255).astype(np.uint8)\n",
    "    adjusted_image = Image.fromarray(adjusted_img_array)\n",
    "    return adjusted_image\n",
    "\n",
    "path_folder = 'C:\\Stuff\\Dataset-creation\\data\\stump-gamma'\n",
    "\n",
    "gamma_increase = 0.2\n",
    "gamma_decrease = 5\n",
    "for folder in os.listdir(path_folder):\n",
    "    value = int(re.findall(r'\\d+', folder)[0])/100\n",
    "    path_image_folder = os.path.join(path_folder, folder, 'images')\n",
    "\n",
    "    train_images = [i for i in os.listdir(path_image_folder) if 'train' in i]\n",
    "    selected_images = random.sample(train_images, int(value * len(train_images)))\n",
    "    for img_name in selected_images:\n",
    "        path_image = os.path.join(path_image_folder, img_name)\n",
    "        noisy_image = None\n",
    "        if random.choice([True, False]):\n",
    "            print(path_image)\n",
    "            noisy_image = adjust_gamma(path_image, gamma_increase)\n",
    "        # For the second half, decrease gamma\n",
    "        else:\n",
    "            noisy_image = adjust_gamma(path_image, gamma_decrease)\n",
    "        noisy_image.save(path_image)\n",
    "    print(f'done {folder} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done stump-every-2\n",
      "done stump-every-3\n",
      "done stump-every-4\n",
      "done stump-every-5\n",
      "done stump-every-6\n",
      "done stump-every-7\n",
      "done stump-every-8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "path_folder = 'C:\\Stuff\\Dataset-creation\\data\\stump-sparce'\n",
    "path_original_tf = 'C:\\Stuff\\Dataset-creation\\data\\stump\\\\transforms.json'\n",
    "\n",
    "for folder in os.listdir(path_folder):\n",
    "    every_num = int(re.findall(r'\\d+', folder)[0])\n",
    "\n",
    "    path_transforms = os.path.join(path_folder, folder, 'transforms.json') \n",
    "    shutil.copy2(path_original_tf, path_transforms)\n",
    "    f = open(path_transforms)\n",
    "    file = json.load(f)\n",
    "    new_frames = []\n",
    "    \n",
    "    i = 0\n",
    "    for frame in file['frames']:\n",
    "\n",
    "        if 'train' in frame['file_path']:\n",
    "            if (i+1) % every_num == 0:\n",
    "                new_frames.append(frame)\n",
    "            i += 1\n",
    "        elif 'eval' in frame['file_path']: \n",
    "            new_frames.append(frame)\n",
    "        else:\n",
    "            raise KeyboardInterrupt\n",
    "        \n",
    "    file['frames'] = new_frames\n",
    "    with open(path_transforms, \"w\") as jsonFile:\n",
    "        json.dump(file, jsonFile, indent=4)     \n",
    "\n",
    "    print(f'done {folder}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done stump-offset-every-2\n",
      "done stump-offset-every-3\n",
      "done stump-offset-every-4\n",
      "done stump-offset-every-5\n",
      "done stump-offset-every-6\n",
      "done stump-offset-every-7\n",
      "done stump-offset-every-8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "path_folder = 'C:\\Stuff\\Dataset-creation\\data\\stump-sparce-offset'\n",
    "path_original_tf = 'C:\\Stuff\\Dataset-creation\\data\\stump-original\\\\transforms.json'\n",
    "\n",
    "for folder in os.listdir(path_folder):\n",
    "    every_num = int(re.findall(r'\\d+', folder)[0])\n",
    "    path_transforms = os.path.join(path_folder, folder, 'transforms.json')\n",
    "    f = open(path_transforms)\n",
    "    file = json.load(f)\n",
    "    new_frames = []\n",
    "    i = 0\n",
    "    for frame in file['frames']:\n",
    "        if 'train' in frame['file_path']:\n",
    "            if (i+1) % every_num == 0:\n",
    "                new_frames.append(frame)\n",
    "            i += 1\n",
    "        elif 'eval' in frame['file_path']: \n",
    "            new_frames.append(frame)\n",
    "        else:\n",
    "            raise KeyboardInterrupt\n",
    "        \n",
    "    file['frames'] = new_frames\n",
    "    with open(path_transforms, \"w\") as jsonFile:\n",
    "        json.dump(file, jsonFile, indent=4)     \n",
    "\n",
    "    print(f'done {folder}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done stump-offset-5-every-2\n",
      "done stump-offset-5-every-3\n",
      "done stump-offset-5-every-4\n",
      "done stump-offset-5-every-5\n",
      "done stump-offset-5-every-6\n",
      "done stump-offset-5-every-7\n",
      "done stump-offset-5-every-8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "path_folder = 'C:\\Stuff\\Dataset-creation\\data\\stump-sparce-offset-5'\n",
    "path_original_tf = 'C:\\Stuff\\Dataset-creation\\data\\stump-original\\\\transforms.json'\n",
    "\n",
    "for folder in os.listdir(path_folder):\n",
    "    every_num = int(re.findall(r'\\d+', folder)[-1])\n",
    "    path_transforms = os.path.join(path_folder, folder, 'transforms.json')\n",
    "    f = open(path_transforms)\n",
    "    file = json.load(f)\n",
    "    new_frames = []\n",
    "    i = 0\n",
    "    for frame in file['frames']:\n",
    "        if 'train' in frame['file_path']:\n",
    "            if (i+1) % every_num == 0:\n",
    "                new_frames.append(frame)\n",
    "            i += 1\n",
    "        elif 'eval' in frame['file_path']: \n",
    "            new_frames.append(frame)\n",
    "        else:\n",
    "            raise KeyboardInterrupt\n",
    "        \n",
    "    file['frames'] = new_frames\n",
    "    with open(path_transforms, \"w\") as jsonFile:\n",
    "        json.dump(file, jsonFile, indent=4)     \n",
    "\n",
    "    print(f'done {folder}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
