{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_project_name_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        yaml_content = file.read()\n",
    "        project_name_start = yaml_content.find('project_name:') + len('project_name:')\n",
    "        project_name_end = yaml_content.find('\\n', project_name_start)\n",
    "        project_name_value = yaml_content[project_name_start:project_name_end].strip()\n",
    "\n",
    "    return project_name_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danko\\miniconda3\\envs\\nerfstudio\\lib\\site-packages\\nerfstudio\\utils\\misc.py:184: RuntimeWarning: Windows does not yet support torch.compile and the performance will be affected.\n",
      "warnings.warn(\n",
      "WRITING THE FILES\n",
      "c:\\Stuff\\Results\\lego_transform.npy\n",
      "SAVING THE ORIENTED POSES BLENDER\n",
      "WRITING THE FILES\n",
      "c:\\Stuff\\Results\\lego_transform.npy\n",
      "SAVING THE ORIENTED POSES BLENDER\n",
      "Setting up training dataset...\n",
      "Caching all 100 images.\n",
      "\n",
      "Loading data batch ----------------------------------------   0% -:--:--\n",
      "Loading data batch ------ ---------------------------------  16% -:--:--\n",
      "Loading data batch ------------ ---------------------------  32% 0:00:01\n",
      "Loading data batch ------------ ---------------------------  32% 0:00:01\n",
      "Loading data batch ------------------------------- --------  78% 0:00:01\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n",
      "\n",
      "Setting up evaluation dataset...\n",
      "Caching all 100 images.\n",
      "\n",
      "Loading data batch ----------------------------------------   0% -:--:--\n",
      "Loading data batch ------ ---------------------------------  16% -:--:--\n",
      "Loading data batch -------------- -------------------------  36% 0:00:01\n",
      "Loading data batch ---------------------- -----------------  56% 0:00:01\n",
      "Loading data batch ------------------------------ ---------  76% 0:00:01\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n",
      "\n",
      "Loading latest checkpoint from load_dir\n",
      "──────────────────────────────────────────────────────── Error ─────────────────────────────────────────────────────────\n",
      "No checkpoint directory found at\n",
      "C:\\Stuff\\Dataset-creation\\notebooks\\outputs_ngp_lego_opt_off\\lego\\instant-ngp\\2024-03-04_000957\\nerfstudio_models,\n",
      "Please make sure the checkpoint exists, they should be generated periodically during training\n",
      "C:\\Users\\danko\\miniconda3\\envs\\nerfstudio\\lib\\site-packages\\nerfstudio\\utils\\misc.py:184: RuntimeWarning: Windows does not yet support torch.compile and the performance will be affected.\n",
      "warnings.warn(\n",
      "WRITING THE FILES\n",
      "c:\\Stuff\\Results\\lego_transform.npy\n",
      "SAVING THE ORIENTED POSES BLENDER\n",
      "WRITING THE FILES\n",
      "c:\\Stuff\\Results\\lego_transform.npy\n",
      "SAVING THE ORIENTED POSES BLENDER\n",
      "Setting up training dataset...\n",
      "Caching all 100 images.\n",
      "\n",
      "Loading data batch ----------------------------------------   0% -:--:--\n",
      "Loading data batch ----------------------------------------   0% -:--:--\n",
      "Loading data batch ------ ---------------------------------  16% -:--:--\n",
      "Loading data batch ------------------------- --------------  63% 0:00:01\n",
      "Loading data batch ----------------------------------- ----  88% 0:00:01\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n",
      "Loading data batch ---------------------------------------- 100% 0:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(command, shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m process\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danko\\miniconda3\\envs\\nerfstudio\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_type = 'instant-ngp'\n",
    "path_outputs = r'C:\\Stuff\\Results\\outputs\\outputs_ngp_lego_opt_off'\n",
    "jsons_output_path = r'C:\\Stuff\\Results\\jsons\\jsons_ngp_lego_opt_off'\n",
    "i = 0\n",
    "# for i, degradation_type in enumerate(os.listdir(path_outputs)[1:]):\n",
    "for degradation_type in os.listdir(path_outputs):\n",
    "    runs = os.path.join(path_outputs, degradation_type, model_type)\n",
    "    # for i, run in enumerate(os.listdir(runs)):\n",
    "    for run in os.listdir(runs):\n",
    "        run_config_path = os.path.join(runs, run, 'config.yml') \n",
    "        project_name = extract_project_name_from_yaml(run_config_path)\n",
    "        path_render = os.path.join(r'C:\\Stuff\\Results\\renders\\renders_ngp_lego_opt_off', run)\n",
    "        \n",
    "        base_command =   f'ns-eval --load-config={run_config_path} ' \\\n",
    "                        f'--output-path={os.path.join(jsons_output_path, project_name)}.json '             \n",
    "        render_command = f'--render-output-path={path_render} '\n",
    "        command = base_command + render_command\n",
    "        \n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        process.wait()\n",
    "        return_code = process.returncode                \n",
    "\n",
    "        file_path = r'C:\\Stuff\\Results\\renders_output_lego_nerfacto_opt_on.txt'\n",
    "        if not os.path.exists(file_path):\n",
    "            open(file_path, 'a').close()\n",
    "        with open(file_path, 'a') as file:\n",
    "            text_to_write = f'The command at {project_name} exited with code: {return_code}\\n'\n",
    "            file.write(text_to_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
